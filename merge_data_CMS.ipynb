{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Lista de palavras ignoradas\n",
    "# Global set of ignored words\n",
    "palavras_ignoradas = {\n",
    "    \"NETO\", \"NEGRI\", \"NOVE\", \"N KM\", \"Niemeyer\", \"NICOLAU\", \"NEREU\", \"NATAL\", \"NELSINA\", \"NILO\", \"Andrade\", \n",
    "    \"N KM430\", \"SALGADO\", \"SALMÃO\", \"NOVICKI\", \"Nébias\", \"NÚMERO\", \"NEVES\", \"NOTARI\", \"NEGRO\", \"NAGANO\", \n",
    "    \"ANDRÉ\", \"NERY\", \"NOBREGA\", \"NAKAZATO\", \"N BRCAO\", \"NEBLINA\", \"NOVEMBRO\", \"SALVESTRINI\", \"APOIO\", \n",
    "    \"SALLES\", \"NOGUEIRA\", \"NY\", \"NASCIMENTO\", \"NACOES\", \"NADER\", \"NICANOR\", \"Andorra\", \"NAZEAZENO\", \n",
    "    \"NORTE\", \"NOBORU\", \"NE\", \"SALES\", \"SALLA\", \"SALLE\", \"NOVELINO\", \"NELSON\", \"NS\", \"NAZARÉ\", \"NUNES\", \n",
    "    \"ANDRE\", \"N ETN\", \"NAGASHIMA\", \"NOSSA\", \"NAZARENO\", \"NORDESTINA\", \"NOBRE\", \"NATANAEL\", \"SALUSTIANO\", \n",
    "    \"ANDRADINA\", \"ANDRADAS\", \"NONOAI\", \"NEGRAS\", \"Noticias\", \"NELSIA\", \"N CH\", \"NATINGUI\", \"NORONHA\", \n",
    "    \"NU1700\", \"NSA\", \"BLUMENAU\", \"N GLEBA\", \"NAVES\", \"ANDREA\", \"SALVADOR\", \"N KM6\", \"NH\", \"NOVA\", \n",
    "    \"SALTINHO\", \"NICOLA\", \"NAGIB\", \"N GALPAO\", \"ANDREAZZA\", \"NASCENTE\", \"NONATO\", \"NAKATA\", \"NAÇOES\", \n",
    "    \"N DIBBI\", \"NA APULCRO\", \"APRIGIO\", \"ANDARAI\", \"NOVAES\", \"NS APARECIDA\", \"NOVIS\", \"NANUQUE\", \n",
    "    \"NARCISO\", \"NABUCO\", \"NCT\", \"SALVATORE\", \"NAZARETH\", \"ANDRELINA\", \"ANDRADE\", \"ANDORRA\", \"NÉBIAS\",\n",
    "    \"NIEMEYER\", \"NOTÍCIAS\", \"NOTICIAS\"\n",
    "}\n",
    "\n",
    "# Function to extract street components (logradouro, number, complement)\n",
    "def extract_number_and_complement(lessee_street):\n",
    "    \n",
    "    # Split the street into words and remove ignored words\n",
    "    palavras = lessee_street.split()\n",
    "    palavras = [palavra for palavra in palavras if palavra.upper() not in palavras_ignoradas]\n",
    "    endereco_limpo = \" \".join(palavras)\n",
    "\n",
    "    # Regex for street type and number/complement / Expressões regulares para detectar e separar os componentes\n",
    "    # Logradouro: Pode ser \"AV\", \"R\", \"EST\", \"ROD\", etc.\n",
    "    logradouro_regex = r\"^(AV|R|EST|ROD|DT|QUADRA|UNIDADE|SÃO|SANTA|VIA|PRAÇA|AL|TRAVESSA|RUA|ALAMEDA|PARQUE|LARGO)[^\\d]+\"\n",
    "    numero_complemento_regex = r\"(\\d+|S/N)(.*)\"\n",
    "\n",
    "    # # Extract street type/ Encontrar o logradouro\n",
    "    logradouro_match = re.match(logradouro_regex, endereco_limpo)\n",
    "    logradouro = logradouro_match.group(0).strip() if logradouro_match else ''\n",
    "\n",
    "    # Extract number and complement/ Encontrar o número e complemento\n",
    "    numero_complemento_match = re.search(numero_complemento_regex, endereco_limpo)\n",
    "    if numero_complemento_match:\n",
    "        numero = numero_complemento_match.group(1).strip()\n",
    "        complemento = numero_complemento_match.group(2).strip()\n",
    "    else:\n",
    "        numero = ''\n",
    "        complemento = ''\n",
    "\n",
    "    # Cleanup complement / Remover vírgulas extra no complemento\n",
    "    complemento = complemento.replace(\",\", \"\")\n",
    "    \n",
    "    # Casos específicos de complementos com mais de uma parte\n",
    "    if \"ANDAR\" in complemento or \"SL\" in complemento or \"CONJ\" in complemento:\n",
    "        complemento = complemento.replace(\"  \", \" \").strip()\n",
    "\n",
    "    return logradouro, numero, complemento\n",
    "\n",
    "# Function to load a DataFrame from an Excel file\n",
    "def load_excel(file_path, sheet_name=None):\n",
    "    return pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "\n",
    "# Define paths and filenames\n",
    "DATA_PATH = 'C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\'\n",
    "FINALIZED_PATH = os.path.join(DATA_PATH, 'finalizados')\n",
    "MASTER_FILE = os.path.join(DATA_PATH, 'PMD-CMS.xlsx')\n",
    "BASE_CEP_FILE = os.path.join(FINALIZED_PATH, 'base_cep_consolidada.xlsx')\n",
    "OUTPUT_FILE = os.path.join(FINALIZED_PATH, 'enderecos_processados.xlsx')\n",
    "SHEET_NAME = 'after synch'\n",
    "\n",
    "\n",
    "df_master = load_excel(MASTER_FILE, sheet_name=SHEET_NAME)\n",
    "\n",
    "# Set headers and select relevant columns\n",
    "HEADERS = df_master.iloc[0, :].tolist()\n",
    "df_master.columns = HEADERS\n",
    "df_master = df_master.iloc[1:,0:13]\n",
    "\n",
    "# Extract number and complement using the extraction function\n",
    "df_master[['Numero', 'Complemento', 'LesseeStreet']] = df_master['LesseeStreet'].apply(\n",
    "    lambda x: pd.Series(extract_number_and_complement(x))\n",
    ")\n",
    "\n",
    "# Select and rename columns\n",
    "SELECTED_COLUMNS = [\n",
    "    'CompanyNumber', 'Branch', \n",
    "    'ContractNumber', 'Bearbeitungsstand', \n",
    "    'Rueckstand', 'LesseeStreet','Numero', \n",
    "    'Complemento','LesseePostCode', 'LesseeCity',\n",
    "    'LesseCountry', 'LesseeCounty',\n",
    "    'LesseeState', 'LesseeName']\n",
    "\n",
    "df_master = df_master.loc[:,SELECTED_COLUMNS]\n",
    "\n",
    "# Load and merge CEP mapping\n",
    "SHEET_NAME = 'CEPS'\n",
    "cep_mapping = pd.read_excel(MASTER_FILE, sheet_name = SHEET_NAME)\n",
    "df_master = df_master.merge(cep_mapping,left_on='LesseePostCode',right_on='CEP_OLD',how='left')\n",
    "\n",
    "# Load and merge validated CEP data\n",
    "FINAL_COLUMNS = [\n",
    "    'CompanyNumber', 'Branch', \n",
    "    'ContractNumber', 'Bearbeitungsstand', \n",
    "    'Rueckstand', 'NewLesseeStreet', \n",
    "    'LesseeStreet','CEP_NEW','Numero', \n",
    "    'Complemento','LesseePostCode', 'LesseeCity',\n",
    "    'LesseCountry', 'LesseeCounty',\n",
    "    'LesseeState', 'LesseeName'\n",
    "    ]\n",
    "df_master[\"NewLesseeStreet\"] = df_master[\"LesseeStreet\"]\n",
    "df_master = df_master.loc[ : , FINAL_COLUMNS ]\n",
    "\n",
    "# Save final DataFrame to Excel\n",
    "BASE_CEP_API = pd.read_excel(BASE_CEP_FILE)\n",
    "CEP_COLUMNS = ['cep_validado', 'logradouro','bairro', 'cidade', 'uf', 'Estado']\n",
    "BASE_CEP_API = BASE_CEP_API.loc[ : , CEP_COLUMNS ]\n",
    "\n",
    "\n",
    "df_master = df_master.merge(BASE_CEP_API, how='left', left_on='CEP_NEW', right_on='cep_validado')\n",
    "FINAL_COLUMNS = [\n",
    "    'CompanyNumber', 'LesseeName','Branch',\n",
    "    'ContractNumber', 'Bearbeitungsstand',\n",
    "    'Rueckstand', 'CEP_NEW', 'NewLesseeStreet','logradouro',\n",
    "    'Numero', 'Complemento', 'bairro', 'cidade',\n",
    "    'uf', 'Estado'\n",
    "]\n",
    "\n",
    "df_master = df_master.loc[ : , FINAL_COLUMNS ]\n",
    "df_master.to_excel(OUTPUT_FILE, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
