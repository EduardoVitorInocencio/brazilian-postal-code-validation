{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "# Lista de palavras ignoradas (já definida)\n",
    "palavras_ignoradas = {\n",
    "    \"NETO\", \"NEGRI\", \"NOVE\", \"N KM\", \"Niemeyer\", \"NICOLAU\", \"NEREU\", \"NATAL\", \"NELSINA\", \"NILO\", \"Andrade\", \n",
    "    \"N KM430\", \"SALGADO\", \"SALMÃO\", \"NOVICKI\", \"Nébias\", \"NÚMERO\", \"NEVES\", \"NOTARI\", \"NEGRO\", \"NAGANO\", \n",
    "    \"ANDRÉ\", \"NERY\", \"NOBREGA\", \"NAKAZATO\", \"N BRCAO\", \"NEBLINA\", \"NOVEMBRO\", \"SALVESTRINI\", \"APOIO\", \n",
    "    \"SALLES\", \"NOGUEIRA\", \"NY\", \"NASCIMENTO\", \"NACOES\", \"NADER\", \"NICANOR\", \"Andorra\", \"NAZEAZENO\", \n",
    "    \"NORTE\", \"NOBORU\", \"NE\", \"SALES\", \"SALLA\", \"SALLE\", \"NOVELINO\", \"NELSON\", \"NS\", \"NAZARÉ\", \"NUNES\", \n",
    "    \"ANDRE\", \"N ETN\", \"NAGASHIMA\", \"NOSSA\", \"NAZARENO\", \"NORDESTINA\", \"NOBRE\", \"NATANAEL\", \"SALUSTIANO\", \n",
    "    \"ANDRADINA\", \"ANDRADAS\", \"NONOAI\", \"NEGRAS\", \"Noticias\", \"NELSIA\", \"N CH\", \"NATINGUI\", \"NORONHA\", \n",
    "    \"NU1700\", \"NSA\", \"BLUMENAU\", \"N GLEBA\", \"NAVES\", \"ANDREA\", \"SALVADOR\", \"N KM6\", \"NH\", \"NOVA\", \n",
    "    \"SALTINHO\", \"NICOLA\", \"NAGIB\", \"N GALPAO\", \"ANDREAZZA\", \"NASCENTE\", \"NONATO\", \"NAKATA\", \"NAÇOES\", \n",
    "    \"N DIBBI\", \"NA APULCRO\", \"APRIGIO\", \"ANDARAI\", \"NOVAES\", \"NS APARECIDA\", \"NOVIS\", \"NANUQUE\", \n",
    "    \"NARCISO\", \"NABUCO\", \"NCT\", \"SALVATORE\", \"NAZARETH\", \"ANDRELINA\", \"ANDRADE\", \"ANDORRA\", \"NÉBIAS\",\n",
    "    \"NIEMEYER\", \"NOTÍCIAS\", \"NOTICIAS\"\n",
    "}\n",
    "\n",
    "def extrair_endereco(lessee_street):\n",
    "    # Remover as palavras ignoradas\n",
    "    palavras = lessee_street.split()\n",
    "    palavras = [palavra for palavra in palavras if palavra.upper() not in palavras_ignoradas]\n",
    "    \n",
    "    # Reconstruir o endereço sem as palavras ignoradas\n",
    "    endereco_limpo = \" \".join(palavras)\n",
    "\n",
    "    # Expressões regulares para detectar e separar os componentes\n",
    "    # Logradouro: Pode ser \"AV\", \"R\", \"EST\", \"ROD\", etc.\n",
    "    logradouro_regex = r\"^(AV|R|EST|ROD|DT|QUADRA|UNIDADE|SÃO|SANTA|VIA|PRAÇA|AL|TRAVESSA|RUA|ALAMEDA|PARQUE|LARGO)[^\\d]+\"\n",
    "    numero_complemento_regex = r\"(\\d+|S/N)(.*)\"\n",
    "\n",
    "    # Encontrar o logradouro\n",
    "    logradouro_match = re.match(logradouro_regex, endereco_limpo)\n",
    "    logradouro = logradouro_match.group(0).strip() if logradouro_match else ''\n",
    "\n",
    "    # Encontrar o número e complemento\n",
    "    numero_complemento_match = re.search(numero_complemento_regex, endereco_limpo)\n",
    "    if numero_complemento_match:\n",
    "        numero = numero_complemento_match.group(1).strip()\n",
    "        complemento = numero_complemento_match.group(2).strip()\n",
    "    else:\n",
    "        numero = ''\n",
    "        complemento = ''\n",
    "\n",
    "    # Ajustes para casos específicos\n",
    "    # Remover vírgulas extra no complemento\n",
    "    complemento = complemento.replace(\",\", \"\")\n",
    "    \n",
    "    # Casos específicos de complementos com mais de uma parte\n",
    "    if \"ANDAR\" in complemento or \"SL\" in complemento or \"CONJ\" in complemento:\n",
    "        complemento = complemento.replace(\"  \", \" \").strip()\n",
    "\n",
    "    return logradouro, numero, complemento\n",
    "\n",
    "path = 'C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\'\n",
    "file_name = 'PMD-CMS.xlsx'\n",
    "full_file_name = path + file_name\n",
    "sheet_name = 'after synch'\n",
    "\n",
    "df_master = pd.read_excel(full_file_name, sheet_name=sheet_name)\n",
    "\n",
    "HEADERS = df_master.iloc[0, :].tolist()\n",
    "\n",
    "df_master.columns = HEADERS\n",
    "df_master = df_master.iloc[1:,0:13]\n",
    "\n",
    "\n",
    "df_master[['Numero', 'Complemento', 'LesseeStreet']] = df_master['LesseeStreet'].apply(lambda x: pd.Series(extract_number_and_complement(x)))\n",
    "\n",
    "COLUMNS = [\n",
    "    'CompanyNumber', 'Branch', \n",
    "    'ContractNumber', 'Bearbeitungsstand', \n",
    "    'Rueckstand', 'LesseeStreet','Numero', \n",
    "    'Complemento','LesseePostCode', 'LesseeCity',\n",
    "    'LesseCountry', 'LesseeCounty',\n",
    "    'LesseeState', 'LesseeName']\n",
    "\n",
    "df_master = df_master.loc[:,COLUMNS]\n",
    "\n",
    "DE_PARA_CEPS = pd.read_excel(full_file_name, sheet_name='CEPS')\n",
    "\n",
    "df_master = df_master.merge(DE_PARA_CEPS,left_on='LesseePostCode',right_on='CEP_OLD',how='left')\n",
    "\n",
    "COLUMNS = [\n",
    "    'CompanyNumber', 'Branch', \n",
    "    'ContractNumber', 'Bearbeitungsstand', \n",
    "    'Rueckstand', 'NewLesseeStreet', 'LesseeStreet','CEP_NEW','Numero', \n",
    "    'Complemento','LesseePostCode', 'LesseeCity',\n",
    "    'LesseCountry', 'LesseeCounty',\n",
    "    'LesseeState', 'LesseeName']\n",
    "\n",
    "df_master[\"NewLesseeStreet\"] = df_master[\"LesseeStreet\"]\n",
    "df_master = df_master.loc[ : , COLUMNS ]\n",
    "\n",
    "path = 'C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\finalizados\\\\'\n",
    "file_name = 'base_cep_consolidada.xlsx'\n",
    "\n",
    "full_file_name = path + file_name\n",
    "BASE_CEP_API = pd.read_excel(full_file_name)\n",
    "\n",
    "COLUMNS = [\n",
    "    'cep_validado', 'logradouro',\n",
    "    'bairro', 'cidade', 'uf', 'Estado'\n",
    "]\n",
    "\n",
    "BASE_CEP_API = BASE_CEP_API.loc[ : , COLUMNS ]\n",
    "\n",
    "df_master = df_master.merge(BASE_CEP_API, how='left', left_on='CEP_NEW', right_on='cep_validado')\n",
    "\n",
    "COLUMNS = [\n",
    "    'CompanyNumber', 'LesseeName','Branch',\n",
    "    'ContractNumber', 'Bearbeitungsstand',\n",
    "    'Rueckstand', 'CEP_NEW', 'NewLesseeStreet','logradouro',\n",
    "    'Numero', 'Complemento', 'bairro', 'cidade',\n",
    "    'uf', 'Estado'\n",
    "]\n",
    "df_master = df_master.loc[ : , COLUMNS ]\n",
    "\n",
    "\n",
    "path = 'C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\finalizados\\\\'\n",
    "file_name = 'enderecos_processados.xlsx'\n",
    "full_file_name = path + file_name\n",
    "\n",
    "df_master.to_excel(full_file_name, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
