{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão do Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.functions import find_cep\n",
    "from math import ceil\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# CARREGAMENTO DO DATAFRAME PRINCIPAL\n",
    "BASE_DIR = \"C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\"\n",
    "INPUT_DIR = os.path.join(BASE_DIR, \"Divididos\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"Completos\")\n",
    "REVIEWED_DIR = os.path.join(BASE_DIR, \"revisados\")\n",
    "FINALIZED_DIR = os.path.join(BASE_DIR, \"finalizados\")\n",
    "MASTER_FILE = os.path.join(BASE_DIR, \"PMD-CMS.xlsx\")\n",
    "FINAL_FILE = os.path.join(FINALIZED_DIR, \"base_cep_consolidada.xlsx\")\n",
    "LINES_PER_FILE = 20\n",
    "\n",
    "path = \"C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\PMD-CMS.xlsx\"\n",
    "sheet_name=\"CEPS\"\n",
    "df = pd.read_excel(path, sheet_name=\"CEPS\")\n",
    "input_dir = 'DataSources\\\\Divididos\\\\'\n",
    "output_dir = 'DataSources\\\\Completos\\\\'\n",
    "\n",
    "# # UF to Estado mapping / Dicionário para mapear siglas de UF para os nomes dos estados corretos\n",
    "UF_TO_ESTADO = {\n",
    "    'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas', 'BA': 'Bahia',\n",
    "    'CE': 'Ceará', 'DF': 'Distrito Federal', 'ES': 'Espírito Santo', 'GO': 'Goiás',\n",
    "    'MA': 'Maranhão', 'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais',\n",
    "    'PA': 'Pará', 'PB': 'Paraíba', 'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "    'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul',\n",
    "    'RO': 'Rondônia', 'RR': 'Roraima', 'SC': 'Santa Catarina', 'SP': 'São Paulo',\n",
    "    'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "}\n",
    "\n",
    "# # Function to find address by CEP / FUNÇÃO PARA OBTER INFORMAÇÕES COM BASE NO CEP\n",
    "def find_cep(cep, cache):\n",
    "    if cep in cache:\n",
    "        return cache[cep]\n",
    "    \n",
    "    else:\n",
    "    # URL_VIA_CEP = f'https://viacep.com.br/ws/{cep}/json/'\n",
    "        URL_VIA_CEP = f'https://opencep.com/v1/{cep}'\n",
    "        try:\n",
    "            answer = requests.get(URL_VIA_CEP, timeout=5)\n",
    "            if answer.ok:\n",
    "                address_ = answer.json()\n",
    "                if \"erro\" in address_:\n",
    "                    cache[cep] = {\n",
    "                        \"cep\":\"\",\n",
    "                        \"logradouro\":\"\",\n",
    "                        \"complemento\":\"\",\n",
    "                        \"bairro\":\"\",\n",
    "                        \"localidade\": \"\",\n",
    "                        \"uf\":\"\",\n",
    "                        \"ibge\":\"\",\n",
    "                        \"erro\":\"INVALID CEP\",\n",
    "                    }\n",
    "                else:\n",
    "                    cache[cep]={\n",
    "                        \"cep\": address_.get(\"cep\",\"\"),\n",
    "                        \"logradouro\":address_.get(\"logradouro\",\"\"),\n",
    "                        \"complemento\":address_.get(\"complemento\",\"\"),\n",
    "                        \"bairro\":address_.get(\"bairro\",\"\"),\n",
    "                        \"localidade\":address_.get(\"localidade\",\"\"),\n",
    "                        \"uf\":address_.get(\"uf\",\"\"),\n",
    "                        \"ibge\":address_.get(\"ibge\",\"\"),\n",
    "                        \"erro\":\"\",\n",
    "                    }\n",
    "            else:\n",
    "                cache[cep] = {\n",
    "                        \"cep\":\"\",\n",
    "                        \"logradouro\":\"\",\n",
    "                        \"complemento\":\"\",\n",
    "                        \"bairro\":\"\",\n",
    "                        \"localidade\": \"\",\n",
    "                        \"uf\":\"\",\n",
    "                        \"ibge\":\"\",\n",
    "                        \"erro\":f\"Erro HTTP {answer.status_code}\",\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            cache[cep] = {\n",
    "                \"cep\":\"\",\n",
    "                        \"logradouro\":\"\",\n",
    "                        \"complemento\":\"\",\n",
    "                        \"bairro\":\"\",\n",
    "                        \"localidade\": \"\",\n",
    "                        \"uf\":\"\",\n",
    "                        \"ibge\":\"\",\n",
    "                \"erro\": \"Erro de conexão\",\n",
    "            }\n",
    "        \n",
    "        # Aguardar para evitar sobrecarregar a API\n",
    "        sleep(0.4) #900 ms    \n",
    "        return cache[cep]\n",
    "\n",
    "\n",
    "# SELECIONAR E LIMPAR A COLUNA DE CEP\n",
    "df = df[['CEP_NEW']]\n",
    "df['CEP_NEW'] = df['CEP_NEW'].str.replace('-','').str.strip()\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Determinar o número de linhas por arquivo (por exemplo, 100 linhas por arquivo)\n",
    "lines_per_file = 20\n",
    "\n",
    "# CALCULAR O NÚMERO DE ARQUIVOS NECESSÁRIOS\n",
    "lines_total = len(df)\n",
    "number_of_files = ceil(lines_total / lines_per_file)\n",
    "\n",
    "# Criar diretório para salvar os arquivos divididos\n",
    "output_dir = 'DataSources\\\\Divididos'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dividir e salvar os arquivos\n",
    "for i in range(number_of_files):\n",
    "    start = i * lines_per_file\n",
    "    end = start + lines_per_file\n",
    "    df_divided =  df.iloc[start:end]\n",
    "    file_name = os.path.join(output_dir, f'file_{i + 1}.xlsx')\n",
    "    df_divided.to_excel(file_name,index=False)\n",
    "\n",
    "\n",
    "# APLICAÇÃO DA FUNÇÃO DESENVOLVIDA\n",
    "i = 1\n",
    "files = glob.glob(f'{input_dir}*.xlsx')\n",
    "\n",
    "cache = {}\n",
    "enderecos = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_excel(file, dtype={\"CEP_NEW\": str})\n",
    "    # Inicializar cache e lista para armazenar os endereços\n",
    "    # Processar cada CEP\n",
    "    for cep in df['CEP_NEW']:\n",
    "        endereco = find_cep(cep,cache=cache)\n",
    "        enderecos.append(endereco)\n",
    "\n",
    "    # Criar DataFrame dos resultados de consulta\n",
    "    enderecos_df = pd.DataFrame(enderecos)\n",
    "    # Concatenar os resultados ao DataFrame original\n",
    "    df_completo = pd.concat([df.reset_index(drop=True), enderecos_df], axis=1)\n",
    "    df_completo.to_excel(\"DataSources\\\\revisados\\\\cep_\" + str(i) + \".xlsx\")\n",
    "    enderecos = []\n",
    "    i+=1\n",
    "\n",
    "\n",
    "# AGRUPANDO ARQUIVOS\n",
    "output_dir = 'DataSources\\\\revisados\\\\'\n",
    "DIR_FILES = os.listdir(output_dir)\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "for file in DIR_FILES:\n",
    "    filepath = output_dir + file\n",
    "    df = pd.read_excel(filepath, dtype={\"CEP_NEW\": str})\n",
    "    df = df.iloc[:,1:]\n",
    "    df_final= pd.concat([df_final,df])\n",
    "\n",
    "output_dir = 'DataSources\\\\finalizados\\\\'\n",
    "file_name = 'base_cep_consolidada.xlsx'\n",
    "full_file_path = output_dir + file_name\n",
    "df_final = df_final[df_final['erro'].isnull()]\n",
    "\n",
    "\n",
    "\n",
    "path_database_master = 'C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\PMD-CMS.xlsx'\n",
    "df_master = pd.read_excel(path_database_master, sheet_name='CEPS')\n",
    "df_master = df_master.merge(df_final,left_on='CEP_NEW', right_on='cep')\n",
    "df_master = df_master[['CEP_OLD','CEP_NEW_x','logradouro', 'complemento','bairro','localidade','uf']]\n",
    "\n",
    "df_master = df_master.rename(columns={\n",
    "                            'CEP_OLD':'cep_antigo',\n",
    "                            'CEP_NEW_x':'cep_validado',\n",
    "                            'localidade':'cidade'\n",
    "                        })\n",
    "\n",
    "# Atualizar a coluna 'Estado' com os nomes corretos baseados na coluna 'UF'\n",
    "df_master['Estado'] = df_master['uf'].map(uf_to_estado)\n",
    "df_master.to_excel(full_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
