{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão do Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento do Dataframe Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CEP_OLD</th>\n",
       "      <th>NUM_CARACT_OLD</th>\n",
       "      <th>CEP_NEW</th>\n",
       "      <th>NUM_CARACT_NEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01331-010</td>\n",
       "      <td>9</td>\n",
       "      <td>01331-010</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CEP_OLD  NUM_CARACT_OLD    CEP_NEW  NUM_CARACT_NEW\n",
       "0  01331-010               9  01331-010               9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\PMD-CMS.xlsx\"\n",
    "sheet_name=\"CEPS\"\n",
    "df = pd.read_excel(path, sheet_name=\"CEPS\")\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionar e limpar coluna de CEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['CEP_NEW']]\n",
    "df['CEP_NEW'] = df['CEP_NEW'].str.replace('-','').str.strip()\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinar o número de linhas por arquivo (por exemplo, 100 linhas por arquivo)\n",
    "lines_per_file = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular o número de arquivos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_total = len(df)\n",
    "number_of_files = ceil(lines_total / lines_per_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diretório para salvar os arquivos divididos\n",
    "output_dir = 'DataSources\\\\Divididos'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir e salvar os arquivos\n",
    "\n",
    "for i in range(number_of_files):\n",
    "    start = i * lines_per_file\n",
    "    end = start + lines_per_file\n",
    "    # print(\"i = \" + str(i) + \" lines = \"+ str(lines_per_file) + \" start = \" + str(start) + \" end = \" + str(end))\n",
    "    df_divided =  df.iloc[start:end]\n",
    "    file_name = os.path.join(output_dir, f'file_{i + 1}.xlsx')\n",
    "    df_divided.to_excel(file_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buscar o CEP com base na função desenvolvida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.functions import find_cep\n",
    "import glob\n",
    "from time import sleep\n",
    "\n",
    "# Diretório de arquivos divididos\n",
    "from urllib import request\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cep(cep, cache):\n",
    "    if cep in cache:\n",
    "        return cache[cep]\n",
    "    \n",
    "    else:\n",
    "    # URL_VIA_CEP = f'https://viacep.com.br/ws/{cep}/json/'\n",
    "        URL_VIA_CEP = f'https://opencep.com/v1/{cep}'\n",
    "        try:\n",
    "            answer = requests.get(URL_VIA_CEP, timeout=5)\n",
    "            if answer.ok:\n",
    "                address_ = answer.json()\n",
    "                if \"erro\" in address_:\n",
    "                    cache[cep] = {\n",
    "                        \"cep\":\"\",\n",
    "                        \"logradouro\":\"\",\n",
    "                        \"complemento\":\"\",\n",
    "                        \"bairro\":\"\",\n",
    "                        \"localidade\": \"\",\n",
    "                        \"uf\":\"\",\n",
    "                        \"ibge\":\"\",\n",
    "                        \"erro\":\"INVALID CEP\",\n",
    "                    }\n",
    "                else:\n",
    "                    cache[cep]={\n",
    "                        \"cep\": address_.get(\"cep\",\"\"),\n",
    "                        \"logradouro\":address_.get(\"logradouro\",\"\"),\n",
    "                        \"complemento\":address_.get(\"complemento\",\"\"),\n",
    "                        \"bairro\":address_.get(\"bairro\",\"\"),\n",
    "                        \"localidade\":address_.get(\"localidade\",\"\"),\n",
    "                        \"uf\":address_.get(\"uf\",\"\"),\n",
    "                        \"ibge\":address_.get(\"ibge\",\"\"),\n",
    "                        \"erro\":\"\",\n",
    "                    }\n",
    "            else:\n",
    "                cache[cep] = {\n",
    "                        \"cep\":\"\",\n",
    "                        \"logradouro\":\"\",\n",
    "                        \"complemento\":\"\",\n",
    "                        \"bairro\":\"\",\n",
    "                        \"localidade\": \"\",\n",
    "                        \"uf\":\"\",\n",
    "                        \"ibge\":\"\",\n",
    "                        \"erro\":f\"Erro HTTP {answer.status_code}\",\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            cache[cep] = {\n",
    "                \"cep\":\"\",\n",
    "                        \"logradouro\":\"\",\n",
    "                        \"complemento\":\"\",\n",
    "                        \"bairro\":\"\",\n",
    "                        \"localidade\": \"\",\n",
    "                        \"uf\":\"\",\n",
    "                        \"ibge\":\"\",\n",
    "                \"erro\": \"Erro de conexão\",\n",
    "            }\n",
    "        \n",
    "        # Aguardar para evitar sobrecarregar a API\n",
    "        return cache[cep]\n",
    "        sleep(0.4) #900 ms    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dir = 'DataSources\\\\Divididos\\\\'\n",
    "output_dir = 'DataSources\\\\Completos\\\\'\n",
    "\n",
    "\n",
    "i = 1\n",
    "files = glob.glob(f'{input_dir}*.xlsx')\n",
    "\n",
    "cache = {}\n",
    "enderecos = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_excel(file, dtype={\"CEP_NEW\": str})\n",
    "    # Inicializar cache e lista para armazenar os endereços\n",
    "    # Processar cada CEP\n",
    "    for cep in df['CEP_NEW']:\n",
    "        endereco = find_cep(cep,cache=cache)\n",
    "        enderecos.append(endereco)\n",
    "\n",
    "    # Criar DataFrame dos resultados de consulta\n",
    "    enderecos_df = pd.DataFrame(enderecos)\n",
    "    # Concatenar os resultados ao DataFrame original\n",
    "    df_completo = pd.concat([df.reset_index(drop=True), enderecos_df], axis=1)\n",
    "    df_completo.to_excel(\"DataSources\\\\revisados\\\\cep_\" + str(i) + \".xlsx\")\n",
    "    enderecos = []\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = 'DataSources\\\\revisados\\\\'\n",
    "DIR_FILES = os.listdir(output_dir)\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "for file in DIR_FILES:\n",
    "    filepath = output_dir + file\n",
    "    df = pd.read_excel(filepath, dtype={\"CEP_NEW\": str})\n",
    "    df = df.iloc[:,1:]\n",
    "    df_final= pd.concat([df_final,df])\n",
    "\n",
    "output_dir = 'DataSources\\\\finalizados\\\\'\n",
    "file_name = 'base_cep_consolidada.xlsx'\n",
    "full_file_path = output_dir + file_name\n",
    "\n",
    "# df_cep_errors = df_final[df_final['erro'].notnull()]\n",
    "df_final = df_final[df_final['erro'].isnull()]\n",
    "\n",
    "# df_final.to_excel(full_file_path, index=False)\n",
    "# df_cep_errors.to_excel(output_dir + 'base_cep_erros.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_database_master = 'C:\\\\Users\\\\edinocencio\\\\DataClenupCmsCrm\\\\DataSources\\\\PMD-CMS.xlsx'\n",
    "\n",
    "df_master = pd.read_excel(path_database_master, sheet_name='CEPS')\n",
    "df_master = df_master.merge(df_final,left_on='CEP_NEW', right_on='cep')\n",
    "df_master = df_master[['CEP_OLD','CEP_NEW_x','logradouro', 'complemento','bairro','localidade','uf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = df_master.rename(columns={\n",
    "                            'CEP_OLD':'cep_antigo',\n",
    "                            'CEP_NEW_x':'cep_validado',\n",
    "                            'localidade':'cidade'\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para mapear siglas de UF para os nomes dos estados corretos\n",
    "uf_to_estado = {\n",
    "    'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas', 'BA': 'Bahia',\n",
    "    'CE': 'Ceará', 'DF': 'Distrito Federal', 'ES': 'Espírito Santo', 'GO': 'Goiás',\n",
    "    'MA': 'Maranhão', 'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais',\n",
    "    'PA': 'Pará', 'PB': 'Paraíba', 'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "    'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul',\n",
    "    'RO': 'Rondônia', 'RR': 'Roraima', 'SC': 'Santa Catarina', 'SP': 'São Paulo',\n",
    "    'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "}\n",
    "\n",
    "# Atualizar a coluna 'Estado' com os nomes corretos baseados na coluna 'UF'\n",
    "df_master['Estado'] = df_master['uf'].map(uf_to_estado)\n",
    "df_master.to_excel(full_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
